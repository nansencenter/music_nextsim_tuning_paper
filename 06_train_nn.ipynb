{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.modules['numpy._core'] = None\n",
    "import numpy as np\n",
    "sys.modules['numpy._core.multiarray'] = np.core.multiarray\n",
    "sys.modules['numpy._core.numeric'] = np.core.numeric\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"10\"\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "\n",
    "from music_nextsim_tuning import train_params, plot_scatter_histo\n",
    "DAY_SECONDS = 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(input_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(16, activation='relu', input_shape=(input_size,)),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_absolute_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.0005)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_func(train_features, train_labels, test_features, test_labels):\n",
    "    input_size = train_features.shape[1]\n",
    "    model = build_and_compile_model(input_size)\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        validation_data=(test_features, test_labels),\n",
    "        verbose=0,\n",
    "        epochs=epochs,\n",
    "        callbacks=[earlystopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdir = './music_matrix/cfg01_m20'\n",
    "idir = './music_matrix/cfg01_m20'\n",
    "max_date = '2007-05-01'\n",
    "good_features = ['hom_01', 'cor_02', 'cor_04', 'ASM_04', 'hom_02', 'div_90', 'ASM_02',\n",
    "       'ene_04', 'ASM_01', 'ene_02', 'con_02', 'ene_01', 'con_01', 'con_04',\n",
    "       'a50_05', 'dis_02', 'dis_04', 'dis_01', 'a90_10', 'mom_3o', 'cnv_50',\n",
    "       'she_50', 'mom_3s', 'mom_2o', 'hom_04', 'a50_10', 'she_90', 'mom_2s',\n",
    "       'a50_15', 'cnv_90', 'mom_1o', 'mom_1s']\n",
    "xlims = {\n",
    "    'compression_factor': [0, 20000],\n",
    "    'C_lab' : [0, 2e6],\n",
    "}\n",
    "\n",
    "bins = 14\n",
    "density = True\n",
    "n_repeats = 10\n",
    "epochs = 300\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ftrs = pd.read_pickle(f'{idir}/ftrs.pickle')\n",
    "inp_lbls = pd.read_pickle(f'{idir}/lbls.pickle')\n",
    "inp_rgps = pd.read_pickle(f'{rdir}/rgps.pickle')\n",
    "print(inp_ftrs.shape, inp_lbls.shape, inp_rgps.shape)\n",
    "\n",
    "inp_lbls = inp_lbls.drop(inp_ftrs[inp_ftrs.date > max_date].index)\n",
    "inp_ftrs = inp_ftrs.drop(inp_ftrs[inp_ftrs.date > max_date].index)\n",
    "inp_rgps = inp_rgps.drop(inp_rgps[inp_rgps.date > max_date].index)\n",
    "print(inp_ftrs.shape, inp_lbls.shape, inp_rgps.shape)\n",
    "\n",
    "inp_ftrs = inp_ftrs[good_features].astype(float)\n",
    "inp_rgps = inp_rgps[good_features].astype(float)\n",
    "print(inp_ftrs.shape, inp_lbls.shape, inp_rgps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs_avg = inp_ftrs.mean()\n",
    "ftrs_std = inp_ftrs.std()\n",
    "lbls_avg = inp_lbls.mean()\n",
    "lbls_std = inp_lbls.std()\n",
    "\n",
    "inp_ftrs = (inp_ftrs - ftrs_avg) / ftrs_std\n",
    "inp_rgps = (inp_rgps - ftrs_avg) / ftrs_std\n",
    "inp_lbls = (inp_lbls - lbls_avg) / lbls_std\n",
    "\n",
    "param_names = list(inp_lbls.columns)\n",
    "print(param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgps_pred_params, test_pred_params, test_labe_params, test_prms_params, train_prms_params = train_params(param_names, inp_ftrs, inp_lbls, inp_rgps, train_func, lbls_std, lbls_avg, n_repeats, epochs, patience, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_histo(param_names, test_labe_params, test_pred_params, rgps_pred_params, bins, density, xlims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{idir}/nn_training.npz', rgps_pred_params=rgps_pred_params, test_pred_params=test_pred_params, test_labe_params=test_labe_params, test_prms_params=test_prms_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
